{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da29fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9a48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(features,label,output_loc,bootstrap_num = 100,data_cut=0,feature_size=0):\n",
    "\n",
    "    \n",
    "    performance = np.zeros((bootstrap_num,))\n",
    "    \n",
    "    \n",
    "    if feature_size:\n",
    "        feature_cut = features.shape[1]-np.abs(feature_size)\n",
    "    else:\n",
    "        feature_cut = 0\n",
    "    \n",
    "    feature_importance = np.zeros((bootstrap_num,features.shape[1]-feature_cut))\n",
    "    feature_importance_rank = np.zeros((bootstrap_num,features.shape[1]-feature_cut))\n",
    "    \n",
    "    \n",
    "    for bootstrap in range(bootstrap_num):        \n",
    "        if data_cut:\n",
    "            \n",
    "            features_cut,trash_a ,label_cut,trash_b  = train_test_split(features, label, train_size=(data_cut/label.shape[0]),shuffle=True,stratify=label,random_state=bootstrap)\n",
    "            training_features, test_features, training_label, test_label = train_test_split(features_cut, label_cut, train_size=0.8,shuffle=True,stratify=label_cut,random_state=bootstrap)\n",
    " \n",
    "        elif feature_size:\n",
    "            if feature_size<0:\n",
    "                training_features, test_features, training_label, test_label = train_test_split(features[:,features.shape[1]+feature_size:], label, train_size=0.8,shuffle=True,stratify=label,random_state=bootstrap)\n",
    "            else:\n",
    "                training_features, test_features, training_label, test_label = train_test_split(features[:,:feature_size], label, train_size=0.8,shuffle=True,stratify=label,random_state=bootstrap)\n",
    "\n",
    "            \n",
    "                \n",
    "        else:   \n",
    "            training_features, test_features, training_label, test_label = train_test_split(features, label, train_size=0.8,shuffle=True,stratify=label,random_state=bootstrap)\n",
    "        X_train = pd.DataFrame(training_features)\n",
    "        X_test = pd.DataFrame(test_features)\n",
    "        y_train =  training_label\n",
    "        y_test  = test_label \n",
    "\n",
    "\n",
    "\n",
    "        model_randomforest = RandomForestClassifier(random_state= 0)    \n",
    "        model_randomforest.fit(X_train, y_train)\n",
    "        predicted = model_randomforest.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,predicted, pos_label=1)\n",
    "        performance[bootstrap] = metrics.auc(fpr, tpr)\n",
    "        \n",
    "        feature_importance[bootstrap,:] = np.abs(model_randomforest.feature_importances_.reshape(-1,))\n",
    "        feature_importance_rank[bootstrap,:] = features.shape[1]- feature_importance[bootstrap].argsort().argsort()\n",
    "        # argsort.argsort는 각 feature의 위치에 해당 feautre의 순위에 반대되는, 즉, 1위는 feature size-1 크기를 배정해줌. \n",
    "        # features.shape[1]에서 뺌으로서, 제일 중요도가 큰 feature의 위치엔 1 이라는 숫자가 들어가게 됨. \n",
    "        # xth number in feature_importance_rank represents the rank of xth feature. The rank is the biggest to 1 and the smallest to feature_size. \n",
    "        \n",
    "    if output_loc[-1]==\"_\":\n",
    "        np.save(output_loc+'performance.npy',performance)\n",
    "        np.save(output_loc+'feature_importance.npy',feature_importance)\n",
    "        np.save(output_loc+'feature_importance_rank.npy',feature_importance_rank)\n",
    "    else:\n",
    "        np.save(output_loc+'/performance.npy',performance)\n",
    "        np.save(output_loc+'/feature_importance.npy',feature_importance)\n",
    "        np.save(output_loc+'/feature_importance_rank.npy',feature_importance_rank)\n",
    "    return performance,feature_importance,feature_importance_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5d1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cut(data_name): \n",
    "    \n",
    "    \n",
    "    features = np.load(\"../dataset/3.preprocessed/%s/features.npy\"%data_name)\n",
    "    label = np.load(\"../dataset/3.preprocessed/%s/label.npy\"%data_name)\n",
    "    \n",
    "    performance_best = np.average(np.load(\"../result/%s/performance.npy\"%data_name))\n",
    "    \n",
    "#     min_data_num = np.int(1/(np.sum(label)/label.shape[0]))+1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if not 'data_cut' in os.listdir(os.getcwd()+\"/../result/%s/\"%data_name):\n",
    "        os.mkdir(\"../result/%s/data_cut\"%data_name)\n",
    "        \n",
    "    grid = np.array(([[label.shape[0],performance_best]]))\n",
    "    np.save(\"../result/%s/data_cut/grid.npy\"%data_name,grid)\n",
    "#     else:\n",
    "#         grid = np.load(\"../result/%s/data_cut/grid.npy\"%data_name)\n",
    "    \n",
    "    current = 0 \n",
    "    while(True):\n",
    "        if grid.shape[0] ==current+1:\n",
    "            if grid[current,1] <=0.55:\n",
    "                print(\"STOP by average AUC under 0.55\")\n",
    "                break\n",
    "#             elif grid[current,0] <min_data_num*2:\n",
    "#                 break\n",
    "            else:\n",
    "                datasize = int(np.round(0.5*grid[current,0]))\n",
    "                # what if AUC<0.55 by 0.5? \n",
    "\n",
    "                try:\n",
    "                    performance,trash_a,trash_b = random_forest(features,label,\"../result/%s/data_cut/%s_\"%(data_name,datasize),100,datasize)  \n",
    "                except:\n",
    "                    print(\"AUC not available \")\n",
    "                    break\n",
    "                \n",
    "                grid = np.append(grid,[[datasize,np.average(performance)]],axis=0)\n",
    "                np.save(\"../result/%s/data_cut/grid.npy\"%data_name,grid)\n",
    "            \n",
    "            \n",
    "            \n",
    "        if grid[current,1]-grid[current+1,1]<=0.05:\n",
    "            current +=1\n",
    "        else:\n",
    "            \n",
    "            if grid[current,0]-grid[current+1,0] ==1:\n",
    "                current+=1\n",
    "                continue\n",
    "            \n",
    "            datasize = int((grid[current,0]+grid[current+1,0])/2)\n",
    "            performance,trash_a,trash_b = random_forest(features,label,\"../result/%s/data_cut/%s_\"%(data_name,datasize),100,datasize)    \n",
    "            grid = np.append(np.append(grid[0:current+1,:].reshape(-1,2),\n",
    "                                       np.array([[datasize,np.average(performance)]]),axis=0),\n",
    "                             grid[current+1:,:].reshape(-1,2),axis=0)\n",
    "            np.save(\"../result/%s/data_cut/grid.npy\"%data_name,grid)\n",
    "            \n",
    "            \n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 no_more_division = False\n",
    "#                 while(True):\n",
    "#                     try:\n",
    "#                         performance,trash_a,trash_b = random_forest(features,label,\"../result/%s/data_cut/%s_\"%(data_name,datasize),100,datasize)  \n",
    "#                         break\n",
    "#                     except:\n",
    "#                         print(\"AUC not available \")\n",
    "#                         if datasize==int(np.round((datasize+int(grid[current,0]))/2)):\n",
    "#                             no_more_division=True\n",
    "#                             break\n",
    "#                         datasize = int(np.round((datasize+int(grid[current,0]))/2))\n",
    "                \n",
    "#                 if no_more_division:\n",
    "#                     break\n",
    "#                 grid = np.append(grid,[[datasize,np.average(performance)]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e571b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cut(data_name): \n",
    "    \n",
    "    features = np.load(\"../dataset/3.preprocessed/%s/features.npy\"%data_name)\n",
    "    label = np.load(\"../dataset/3.preprocessed/%s/label.npy\"%data_name)\n",
    "    \n",
    "    performance_best = np.average(np.load(\"../result/%s/performance.npy\"%data_name))\n",
    "    \n",
    "    \n",
    "    if not 'feature_cut' in os.listdir(os.getcwd()+\"/../result/%s/\"%data_name):\n",
    "        os.mkdir(\"../result/%s/feature_cut\"%data_name)\n",
    "        \n",
    "    grid = np.array(([[features.shape[1],performance_best]]))\n",
    "    np.save(\"../result/%s/feature_cut/grid.npy\"%data_name,grid)\n",
    "\n",
    "    \n",
    "    current = 0 \n",
    "    while(True):\n",
    "        # \n",
    "        if grid.shape[0] ==current+1:\n",
    "            if grid[current,1] <=0.55:\n",
    "                break\n",
    "#             elif grid[current,0] <=features.shape[1]:\n",
    "#                 break\n",
    "            elif grid[current,0] <= 2:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                featuresize = int(0.5*grid[current,0])                \n",
    "                \n",
    "                try:\n",
    "                    performance,trash_a,trash_b = random_forest(features,label,\"../result/%s/feature_cut/%s_\"%(data_name,featuresize),100,0,-featuresize)   \n",
    "                except:\n",
    "                    print(\"AUC not available \")\n",
    "                    break\n",
    "                \n",
    "#                 performance,trash_a,trash_b = random_forest(features,label,\"../result/%s/feature_cut/%s_\"%(data_name,featuresize),100,0,-featuresize)    \n",
    "                grid = np.append(grid,[[featuresize,np.average(performance)]],axis=0)\n",
    "                np.save(\"../result/%s/feature_cut/grid.npy\"%data_name,grid)\n",
    "            \n",
    "            \n",
    "        if grid[current,1]-grid[current+1,1]<=0.05:\n",
    "            current +=1\n",
    "        else:\n",
    "            \n",
    "            if abs(grid[current,0]-grid[current+1,0]) ==1:\n",
    "                current+=1\n",
    "                continue\n",
    "            \n",
    "            featuresize = int((grid[current,0]+grid[current+1,0])/2)\n",
    "            performance,trash_a,trash_b = random_forest(features,label,\"../result/%s/feature_cut/%s_\"%(data_name,featuresize),100,0,-featuresize)    \n",
    "            grid = np.append(np.append(grid[0:current+1,:].reshape(-1,2),\n",
    "                                       np.array([[featuresize,np.average(performance)]]),axis=0),\n",
    "                             grid[current+1:,:].reshape(-1,2),axis=0)\n",
    "            np.save(\"../result/%s/feature_cut/grid.npy\"%data_name,grid)\n",
    "            \n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c801bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc42ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51c0a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.65400000e+03, 9.68915528e-01],\n",
       "       [1.32700000e+03, 9.63723427e-01],\n",
       "       [6.63000000e+02, 9.60212585e-01],\n",
       "       [3.31000000e+02, 9.54650974e-01],\n",
       "       [1.65000000e+02, 9.36464286e-01],\n",
       "       [8.20000000e+01, 9.09285714e-01],\n",
       "       [4.10000000e+01, 8.66250000e-01],\n",
       "       [2.00000000e+01, 8.40000000e-01],\n",
       "       [1.70000000e+01, 8.08333333e-01],\n",
       "       [1.60000000e+01, 8.48333333e-01],\n",
       "       [1.50000000e+01,            nan],\n",
       "       [1.40000000e+01,            nan],\n",
       "       [1.30000000e+01,            nan],\n",
       "       [1.20000000e+01,            nan],\n",
       "       [1.10000000e+01, 8.02500000e-01],\n",
       "       [1.00000000e+01,            nan]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # loc = \"real_1_IBD\"\n",
    "# # loc = \"real_1_IBD_lowcorr_0.5\"\n",
    "# # loc = \"real_1_IBD_lowcorr_0.3\"\n",
    "# # loc = \"real_1_IBD_lowcorr_0.2\"\n",
    "# loc = \"real_2_RSV\"\n",
    "# # loc = \"real_3_perio_health\"\n",
    "# # loc = \"real_4_DM\"\n",
    "# # loc = \"real_5_DR\"\n",
    "# # loc = \"real_6_HF\"\n",
    "# # loc = \"real_7_PK\"\n",
    "# # loc = \"real_8_TS\"\n",
    "# # loc = \"real_9_HT\"\n",
    "# # loc = \"real_10_perio_nutrition\"\n",
    "# # loc = \"real_11_BC\"\n",
    "\n",
    "\n",
    "# feature_cut(\"%s\"%loc)\n",
    "# data_cut(\"%s\"%loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea17769a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15084/714601162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_cut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15084/225825207.py\u001b[0m in \u001b[0;36mdata_cut\u001b[1;34m(data_name)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mdatasize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mperformance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrash_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrash_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"../result/%s/data_cut/%s_\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatasize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatasize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatasize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../result/%s/data_cut/grid.npy\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15084/4196648383.py\u001b[0m in \u001b[0;36mrandom_forest\u001b[1;34m(features, label, output_loc, bootstrap_num, data_cut, feature_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mfeatures_cut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrash_a\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlabel_cut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrash_b\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_cut\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtraining_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_cut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_cut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_cut\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfeature_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2195\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2197\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2199\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \"\"\"\n\u001b[0;32m   1386\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1713\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1715\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1716\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf3358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856234b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf4504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
