{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "# from ipynb.fs.full.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "import function.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generated_1', 'generated_2', 'generated_3', 'real_1_IBD', 'real_2_DR', 'real_3_HF', 'real_4_TS', 'real_5_HT', 'real_6_BC', 'real_7_MS']\n"
     ]
    }
   ],
   "source": [
    "folder_dir = '../2.array'\n",
    "\n",
    "list_data = os.listdir(folder_dir)\n",
    "print(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data=['real_7_MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# list_num = 1\n",
    "\n",
    "\n",
    "# print(list_data)\n",
    "# loc = list_data[list_num]\n",
    "# print(loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arranging the dataset from best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Features, importance, average rank everything should be arranged by its importance\n",
    "## -In case of correlation reduction, the importance should be re-caculated and the arrangement should be redone\n",
    "## -By data cutting and feature cutting, the stability will be compared by the rank in the best model\n",
    "## -However, in case of generated dataset, the arrangement and comparison should be done by the absolute rank, as we know the answer\n",
    "## -Which means, the importance in the best model will not be used. Only the performance is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_7_MS\n",
      "Correlation cut start\n",
      "Correlation result: any correlation>standard?\n",
      "0\n",
      "Number of features left: \n",
      "11\n",
      "Correlation result: any correlation>standard?\n",
      "0\n",
      "Number of features left: \n",
      "17\n",
      "Correlation result: any correlation>standard?\n",
      "0\n",
      "Number of features left: \n",
      "19\n",
      "Correlation result: any correlation>standard?\n",
      "0\n",
      "Number of features left: \n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for loc in list_data:\n",
    "\n",
    "    print(loc)\n",
    "    # Data Call\n",
    "    data_loc = \"../2.array/\"+loc\n",
    "    features = np.load(data_loc+'/features.npy')\n",
    "    label = np.load(data_loc+'/label.npy')\n",
    "\n",
    "\n",
    "    # Building Directory\n",
    "    data_loc = \"../3.preprocessed/\"+loc\n",
    "    output_loc = \"../../result/\"+loc\n",
    "\n",
    "    if not os.path.exists(data_loc):\n",
    "        os.makedirs(data_loc)\n",
    "    if not os.path.exists(data_loc+\"/corr_cut\"):\n",
    "        os.makedirs(data_loc+\"/corr_cut\")\n",
    "\n",
    "    if not os.path.exists(output_loc):\n",
    "        os.makedirs(output_loc)\n",
    "    if not os.path.exists(output_loc+\"/corr_cut\"):\n",
    "        os.makedirs(output_loc+\"/corr_cut\")\n",
    "\n",
    "\n",
    "    # Model Training\n",
    "    performance,feature_importance,feature_importance_rank = function.functions.random_forest(features,label,output_loc)\n",
    "\n",
    "    # Arrange by feature importance\n",
    "    average_importance = np.average(feature_importance,axis=0)\n",
    "    if loc == 'generated_1':\n",
    "        average_importance = np.arange(features.shape[1])\n",
    "    \n",
    "    arranged_features = features[:,average_importance.argsort()[::-1]].copy()\n",
    "\n",
    "\n",
    "    np.save(data_loc+'/features.npy',arranged_features)\n",
    "    np.save(data_loc+'/label.npy',label)\n",
    "\n",
    "    np.save(output_loc+\"/performance.npy\",performance)\n",
    "    np.save(output_loc+\"/feature_importance.npy\",feature_importance[:,average_importance.argsort()[::-1]])\n",
    "    np.save(output_loc+\"/feature_importance_rank.npy\",feature_importance_rank[:,average_importance.argsort()[::-1]])\n",
    "\n",
    "    if loc == 'generated_1' or loc == 'generated_2' or loc == 'generated_2':\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    print(\"Correlation cut start\")\n",
    "    \n",
    "    for corr_standard in [0.3,0.5,0.7,0.9]:\n",
    "\n",
    "\n",
    "        features = np.load(data_loc+'/features.npy')\n",
    "        label = np.load(data_loc+'/label.npy')\n",
    "\n",
    "\n",
    "        corr_data_loc = data_loc+\"/corr_cut/%s\"%corr_standard\n",
    "        corr_output_loc = output_loc +\"/corr_cut/%s\"%corr_standard \n",
    "\n",
    "        if not os.path.exists(corr_data_loc):\n",
    "            os.makedirs(corr_data_loc)\n",
    "\n",
    "        if not os.path.exists(corr_output_loc):\n",
    "            os.makedirs(corr_output_loc)\n",
    "\n",
    "\n",
    "        finish_work = False\n",
    "        while True:\n",
    "            dataframe = pd.DataFrame(features)\n",
    "            corr_matrix = dataframe.corr(method = 'pearson').abs()\n",
    "            corr_matrix =  corr_matrix.to_numpy()\n",
    "            for index_target in range(features.shape[1]):\n",
    "                \n",
    "                if index_target==(features.shape[1]-1):\n",
    "                    finish_work = True\n",
    "                    break                    \n",
    "                \n",
    "                corr_loc = (corr_matrix[index_target,:]>=corr_standard)\n",
    "                if np.sum(corr_loc)==1:\n",
    "                    continue\n",
    "                else:\n",
    "                    non_corr_loc = (corr_matrix[index_target,:]<corr_standard)\n",
    "                    non_corr_loc[index_target] =True\n",
    "                    features = features[:,non_corr_loc]\n",
    "                    break\n",
    "            if finish_work:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#         # Corr matrix\n",
    "#         dataframe = pd.DataFrame(features)\n",
    "# #         dataframe = dataframe.replace(0,np.nan)\n",
    "#         corr_matrix = dataframe.corr(method = 'pearson').abs()\n",
    "# #         corr_matrix = corr_matrix.replace(np.nan,0)\n",
    "#         corr_matrix =  corr_matrix.to_numpy()\n",
    "\n",
    "#         temp_features = features.copy()\n",
    "#         temp_corr = corr_matrix.copy()\n",
    "\n",
    "#         corr_count = 0\n",
    "#         for i in range(features.shape[1]):\n",
    "#             if np.sum(temp_corr[i-corr_count,:]>=corr_standard)>1:\n",
    "#                 temp_features = np.delete(temp_features,i-corr_count,axis=1)\n",
    "#                 temp_corr = pd.DataFrame(temp_features).corr(method = 'pearson').abs().to_numpy()\n",
    "#                 corr_count+=1\n",
    "\n",
    "#         features = temp_features\n",
    "        \n",
    "        \n",
    "        dataframe = pd.DataFrame(features)\n",
    "        corr_matrix = dataframe.corr(method = 'pearson').abs()\n",
    "        print(\"Correlation result: any correlation>standard?\")\n",
    "        print(np.sum(np.sum(corr_matrix>=corr_standard))-features.shape[1])\n",
    "        print(\"Number of features left: \")\n",
    "        print(features.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        performance,feature_importance,feature_importance_rank = function.functions.random_forest(features,label,corr_output_loc)\n",
    "\n",
    "        # Arrange by feature importance\n",
    "        average_importance = np.average(feature_importance,axis=0)\n",
    "        arranged_features = features[:,average_importance.argsort()[::-1]].copy()\n",
    "\n",
    "        np.save(corr_data_loc+'/features.npy',arranged_features)\n",
    "        np.save(corr_data_loc+'/label.npy',label)\n",
    "\n",
    "        np.save(corr_output_loc+\"/performance.npy\",performance)\n",
    "        np.save(corr_output_loc+\"/feature_importance.npy\",feature_importance[:,average_importance.argsort()[::-1]])\n",
    "        np.save(corr_output_loc+\"/feature_importance_rank.npy\",feature_importance_rank[:,average_importance.argsort()[::-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2009, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Generation from real data -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## -Feature importance calculated by real dataset are used for coefficient \n",
    "## -As we know the coefficient, the features don't need to be re-arranged, just following arranged real dataset\n",
    "## -The comparison by cutting will be done by absolute rank, top from the first -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_1_IBD\n",
      "Original number of positive\n",
      "702\n",
      "Generated number of positive\n",
      "702\n",
      "Original number of positive\n",
      "702\n",
      "Original number of positive\n",
      "702\n",
      "Original number of positive\n",
      "702\n",
      "Original number of positive\n",
      "702\n",
      "real_2_DR\n",
      "Original number of positive\n",
      "611\n",
      "Generated number of positive\n",
      "611\n",
      "Original number of positive\n",
      "611\n",
      "Original number of positive\n",
      "611\n",
      "Original number of positive\n",
      "611\n",
      "Original number of positive\n",
      "611\n",
      "real_3_HF\n",
      "Original number of positive\n",
      "96\n",
      "Generated number of positive\n",
      "96\n",
      "Original number of positive\n",
      "96\n",
      "Original number of positive\n",
      "96\n",
      "Original number of positive\n",
      "96\n",
      "Original number of positive\n",
      "96\n",
      "real_4_PK\n",
      "Original number of positive\n",
      "147\n",
      "Generated number of positive\n",
      "147\n",
      "Original number of positive\n",
      "147\n",
      "Original number of positive\n",
      "147\n",
      "Original number of positive\n",
      "147\n",
      "Original number of positive\n",
      "147\n",
      "real_5_TS\n",
      "Original number of positive\n",
      "70\n",
      "Generated number of positive\n",
      "70\n",
      "Original number of positive\n",
      "70\n",
      "Original number of positive\n",
      "70\n",
      "Original number of positive\n",
      "70\n",
      "Original number of positive\n",
      "70\n",
      "real_6_HT\n",
      "Original number of positive\n",
      "212\n",
      "Generated number of positive\n",
      "212\n",
      "Original number of positive\n",
      "212\n",
      "Original number of positive\n",
      "212\n",
      "Original number of positive\n",
      "212\n",
      "Original number of positive\n",
      "212\n",
      "real_7_BC\n",
      "Original number of positive\n",
      "47\n",
      "Generated number of positive\n",
      "47\n",
      "Original number of positive\n",
      "47\n",
      "Original number of positive\n",
      "47\n",
      "Original number of positive\n",
      "47\n",
      "Original number of positive\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "# for loc in list_data:\n",
    "#     if loc == 'generated_1':\n",
    "#         continue\n",
    "\n",
    "#     print(loc)\n",
    "    \n",
    "#     data_loc = \"../3.preprocessed/\"+loc\n",
    "#     output_loc = \"../../result/\"+loc\n",
    "\n",
    "#     features = np.load(data_loc+'/features.npy')\n",
    "#     label = np.load(data_loc+'/label.npy')\n",
    "\n",
    "#     arranged_importance = np.load(output_loc+\"/feature_importance.npy\")\n",
    "    \n",
    "#     arranged_importance = np.average(arranged_importance,axis=0)\n",
    "    \n",
    "\n",
    "#     # new loc\n",
    "#     loc_generate = \"generated_\"+loc\n",
    "#     data_loc = \"../3.preprocessed/\"+loc_generate\n",
    "#     output_loc = \"../../result/\"+loc_generate\n",
    "\n",
    "#     if not os.path.exists(data_loc):\n",
    "#         os.makedirs(data_loc)\n",
    "\n",
    "#     if not os.path.exists(data_loc+\"/corr_cut\"):\n",
    "#         os.makedirs(data_loc+\"/corr_cut\")\n",
    "\n",
    "#     if not os.path.exists(output_loc):\n",
    "#         os.makedirs(output_loc)\n",
    "#     if not os.path.exists(output_loc+\"/corr_cut\"):\n",
    "#         os.makedirs(output_loc+\"/corr_cut\")\n",
    "\n",
    "\n",
    "\n",
    "#     generated_label = np.zeros((label.shape[0],))\n",
    "#     for index in range(label.shape[0]):\n",
    "#         generated_label[index] = np.sum(np.multiply(features[index,:],arranged_importance))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     binary_generated_label =np.zeros((generated_label.shape[0],))\n",
    "#     print(\"Original number of positive\")\n",
    "#     print(int(np.sum(label)))\n",
    "#     standard = generated_label[generated_label.argsort()[::-1]][int(np.sum(label))]\n",
    "#     loc_up = (generated_label>standard)\n",
    "#     loc_down = (generated_label<=standard)\n",
    "#     binary_generated_label[loc_up]  =1\n",
    "#     binary_generated_label[loc_down] =0\n",
    "\n",
    "\n",
    "#     label = binary_generated_label\n",
    "\n",
    "#     print(\"Generated number of positive\")\n",
    "#     print(int(np.sum(label)))\n",
    "\n",
    "#     performance,feature_importance,feature_importance_rank = function.functions.random_forest(features,label,output_loc)\n",
    "\n",
    "#     np.save(data_loc+'/features.npy',features)\n",
    "#     np.save(data_loc+'/label.npy',label)\n",
    "\n",
    "\n",
    "#     # 원래의 arranged된 importance를 가져와서 저장\n",
    "#     output_loc = \"../../result/\"+loc\n",
    "#     arranged_importance = np.load(output_loc+\"/feature_importance.npy\")\n",
    "#     arranged_importance_rank = np.load(output_loc+\"/feature_importance_rank.npy\")\n",
    "\n",
    "#     output_loc = \"../../result/\"+loc_generate\n",
    "\n",
    "#     np.save(output_loc+\"/performance.npy\",performance)\n",
    "#     np.save(output_loc+\"/feature_importance.npy\",arranged_importance)\n",
    "#     np.save(output_loc+\"/feature_importance_rank.npy\",arranged_importance_rank)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     for corr_standard in [0.3,0.5,0.7,0.9]:\n",
    "\n",
    "#         corr_data_loc = data_loc+\"/corr_cut/%s\"%corr_standard\n",
    "#         corr_output_loc = output_loc +\"/corr_cut/%s\"%corr_standard \n",
    "\n",
    "#         if not os.path.exists(corr_data_loc):\n",
    "#             os.makedirs(corr_data_loc)\n",
    "#         if not os.path.exists(corr_output_loc):\n",
    "#             os.makedirs(corr_output_loc)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "#         # corr cut 된, arranged 된 original data를 가져옴\n",
    "            \n",
    "#         org_data_loc = \"../3.preprocessed/\"+loc+\"/corr_cut/%s\"%corr_standard\n",
    "#         org_output_loc = \"../../result/\"+loc+\"/corr_cut/%s\"%corr_standard\n",
    "\n",
    "#         features = np.load(org_data_loc+'/features.npy')\n",
    "#         label = np.load(org_data_loc+'/label.npy')\n",
    "#         feature_importance = np.load(org_output_loc+\"/feature_importance.npy\")\n",
    "#         arranged_importance = np.average(feature_importance,axis=0)\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "#         generated_label = np.zeros((label.shape[0],))\n",
    "#         for index in range(label.shape[0]):\n",
    "#             generated_label[index] = np.sum(np.multiply(features[index,:],arranged_importance))\n",
    "\n",
    "\n",
    "#         binary_generated_label =np.zeros((generated_label.shape[0],))\n",
    "#         print(\"Original number of positive\")\n",
    "#         print(int(np.sum(label)))\n",
    "#         standard = generated_label[generated_label.argsort()[::-1]][int(np.sum(label))]\n",
    "#         loc_up = (generated_label>standard)\n",
    "#         loc_down = (generated_label<=standard)\n",
    "#         binary_generated_label[loc_up]  =1\n",
    "#         binary_generated_label[loc_down] =0\n",
    "\n",
    "#         label = binary_generated_label\n",
    "\n",
    "            \n",
    "#         performance,feature_importance,feature_importance_rank = function.functions.random_forest(features,label,corr_output_loc)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "#         np.save(corr_data_loc+'/features.npy',features)\n",
    "#         np.save(corr_data_loc+'/label.npy',label)\n",
    "\n",
    "#         np.save(corr_output_loc+\"/performance.npy\",performance)\n",
    "        \n",
    "        \n",
    "#         # 원래의 arranged된 importance를 가져와서 저장\n",
    "#         feature_importance = np.load(org_output_loc+\"/feature_importance.npy\")\n",
    "#         feature_importance_rank = np.load(org_output_loc+\"/feature_importance_rank.npy\")\n",
    "#         np.save(corr_output_loc+\"/feature_importance.npy\",feature_importance)\n",
    "#         np.save(corr_output_loc+\"/feature_importance_rank.npy\",feature_importance_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
